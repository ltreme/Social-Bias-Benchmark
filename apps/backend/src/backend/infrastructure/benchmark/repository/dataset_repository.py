"""Repository for dataset data access."""

from __future__ import annotations

import json
from typing import Any, Dict, List, Optional

from backend.infrastructure.storage.models import (
    AdditionalPersonaAttributes,
    AttrGenerationRun,
    BenchmarkRun,
    CounterfactualLink,
    Dataset,
    DatasetPersona,
    Model,
    Persona,
)


class DatasetRepository:
    """Handles database queries for datasets."""

    def list_all_datasets(self) -> List[Dataset]:
        """List all datasets.

        Returns:
            List of Dataset models
        """
        return list(Dataset.select())

    def get_dataset_by_id(self, dataset_id: int) -> Dataset | None:
        """Get a dataset by ID.

        Args:
            dataset_id: The dataset ID

        Returns:
            Dataset or None if not found
        """
        return Dataset.get_or_none(Dataset.id == dataset_id)

    def count_personas_in_dataset(self, dataset_id: int) -> int:
        """Count personas in a dataset.

        Args:
            dataset_id: The dataset ID

        Returns:
            Number of personas in the dataset
        """
        return (
            DatasetPersona.select()
            .where(DatasetPersona.dataset_id == dataset_id)
            .count()
        )

    def get_latest_attrgen_run(self, dataset_id: int) -> AttrGenerationRun | None:
        """Get the latest attribute generation run for a dataset.

        Args:
            dataset_id: The dataset ID

        Returns:
            Latest AttrGenerationRun or None
        """
        return (
            AttrGenerationRun.select()
            .where(AttrGenerationRun.dataset_id == dataset_id)
            .order_by(AttrGenerationRun.id.desc())
            .first()
        )

    def count_attributes_by_key(self, dataset_id: int, attribute_key: str) -> int:
        """Count personas with a specific attribute key in a dataset.

        Args:
            dataset_id: The dataset ID
            attribute_key: The attribute key to count

        Returns:
            Number of personas with this attribute
        """
        return (
            AdditionalPersonaAttributes.select()
            .join(
                DatasetPersona,
                on=(
                    DatasetPersona.persona_id
                    == AdditionalPersonaAttributes.persona_uuid_id
                ),
            )
            .where(
                (DatasetPersona.dataset_id == dataset_id)
                & (AdditionalPersonaAttributes.attribute_key == attribute_key)
            )
            .count()
        )

    def get_enrichment_stats(self, dataset_id: int) -> Dict[str, int]:
        """Get enrichment statistics for a dataset.

        Args:
            dataset_id: The dataset ID

        Returns:
            Dictionary with counts for name, appearance, biography
        """
        stats = {}
        for key in ["name", "appearance", "biography"]:
            stats[f"{key}_n"] = self.count_attributes_by_key(dataset_id, key)
        return stats

    def list_benchmark_runs_for_dataset(self, dataset_id: int) -> List[BenchmarkRun]:
        """List benchmark runs for a dataset.

        Args:
            dataset_id: The dataset ID

        Returns:
            List of BenchmarkRun ordered by most recent first
        """
        return list(
            BenchmarkRun.select()
            .join(Model)
            .where(BenchmarkRun.dataset_id == dataset_id)
            .order_by(BenchmarkRun.id.desc())
        )

    def delete_dataset_with_cascade(self, dataset_id: int) -> Dict[str, int]:
        """Delete a dataset and all associated artifacts.

        Args:
            dataset_id: The dataset ID to delete

        Returns:
            Dictionary with deletion statistics
        """
        from backend.infrastructure.storage.db import transaction

        stats: Dict[str, int] = {
            "deleted_attr_rows": 0,
            "deleted_attr_runs": 0,
            "deleted_cf_links": 0,
            "deleted_dataset": 0,
            "deleted_orphan_personas": 0,
        }

        with transaction():
            # 1) Remove AdditionalPersonaAttributes generated by runs of this dataset
            run_ids = [
                int(r.id)
                for r in AttrGenerationRun.select(AttrGenerationRun.id).where(
                    AttrGenerationRun.dataset_id == dataset_id
                )
            ]
            if run_ids:
                stats["deleted_attr_rows"] = int(
                    AdditionalPersonaAttributes.delete()
                    .where(
                        AdditionalPersonaAttributes.attr_generation_run_id.in_(run_ids)
                    )
                    .execute()
                    or 0
                )
            stats["deleted_attr_runs"] = int(
                AttrGenerationRun.delete()
                .where(AttrGenerationRun.dataset_id == dataset_id)
                .execute()
                or 0
            )

            # 2) Remove counterfactual links for this dataset
            stats["deleted_cf_links"] = int(
                CounterfactualLink.delete()
                .where(CounterfactualLink.dataset_id == dataset_id)
                .execute()
                or 0
            )

            # 3) Delete dataset (CASCADE to DatasetPersona, BenchmarkRun, BenchmarkResult)
            stats["deleted_dataset"] = int(
                Dataset.delete().where(Dataset.id == dataset_id).execute() or 0
            )

            # 4) Remove personas that are no longer members of any dataset
            member_subq = DatasetPersona.select(DatasetPersona.persona_id).distinct()
            orphan_personas = Persona.select(Persona.uuid).where(
                ~(Persona.uuid.in_(member_subq))
            )
            orphan_ids = [p.uuid for p in orphan_personas]
            if orphan_ids:
                stats["deleted_orphan_personas"] = int(
                    Persona.delete().where(Persona.uuid.in_(orphan_ids)).execute() or 0
                )

        return stats

    def delete_dataset_chunked(self, dataset_id: int) -> Dict[str, int]:
        """Delete a dataset in chunks (for very large datasets).

        Args:
            dataset_id: The dataset ID to delete

        Returns:
            Dictionary with deletion statistics
        """
        from backend.infrastructure.storage.db import get_db, transaction

        stats: Dict[str, int] = {
            "deleted_attr_rows": 0,
            "deleted_attr_runs": 0,
            "deleted_cf_links": 0,
            "deleted_dataset": 0,
            "deleted_orphan_personas": 0,
        }

        with transaction():
            # Steps 1-3 same as above
            run_ids = [
                int(r.id)
                for r in AttrGenerationRun.select(AttrGenerationRun.id).where(
                    AttrGenerationRun.dataset_id == dataset_id
                )
            ]
            if run_ids:
                AdditionalPersonaAttributes.delete().where(
                    AdditionalPersonaAttributes.attr_generation_run_id.in_(run_ids)
                ).execute()
                AttrGenerationRun.delete().where(
                    AttrGenerationRun.id.in_(run_ids)
                ).execute()

            CounterfactualLink.delete().where(
                CounterfactualLink.dataset_id == dataset_id
            ).execute()

            Dataset.delete().where(Dataset.id == dataset_id).execute()

        # 4) Cleanup orphan personas in chunks
        db = get_db()
        fetch_sql = (
            "WITH c AS (SELECT p.uuid FROM persona p "
            "LEFT JOIN datasetpersona dp ON dp.persona_id = p.uuid "
            "WHERE dp.persona_id IS NULL LIMIT 5000) "
            "SELECT uuid FROM c"
        )
        deleted_total = 0
        while True:
            cur = db.execute_sql(fetch_sql)
            rows = cur.fetchall()
            if not rows:
                break
            ids = [r[0] for r in rows]
            Persona.delete().where(Persona.uuid.in_(ids)).execute()
            deleted_total += len(ids)

        stats["deleted_orphan_personas"] = deleted_total
        return stats

    def parse_config_json(self, dataset: Dataset) -> Dict[str, Any] | None:
        """Parse config JSON from a dataset.

        Args:
            dataset: The dataset model

        Returns:
            Parsed config or None
        """
        if not dataset.config_json:
            return None
        try:
            return json.loads(dataset.config_json)
        except Exception:
            return None
